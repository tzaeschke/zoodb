MAJOR:
- Read-objects w/o instantiation -> Allows reading DB with evolved classes!
- NOT in queries
- WeakRefs for IndexPages (use additional fixed-ref to avoid collection if page is dirty
- WeakRefs for objects. -> PrimLongLIMap<Long,WeakRef<ZooPCImpl>> ?
- Other query stuff
- Schema evolution
- Client-Server mode
- Think about SCO double-serialization. Can that be sensibly avoided???
  


URGENT:
- Check that dropInstance/deleteAll remove entries from ALL indices (also POS and FIELD)!
- Why does it take so much longer if indexes/classes are removed as well? Because index usage takes
  time? -> Still slower if indexes are disabled in test!!!!!
  -> Also dropInstances is sometimes slower (1 sec.) than delete?!?!? SHould be faster?

- In DataDeSerializer, don't use cache.getSchema(Node, x), because that requires an
  additional HashMap lookup. Instead use locally stored version of schemas for that node.
  -> May only make sense if Deserializer is only created once per session(?). 

COPYRIGHT
- PrimLongMapLI
- PrimLongTreeMap
- WeakIdentityHashMap

DataSinks
- See TODOs in DataSink and DataDeleteSink


BCE
- Efficient insertion of makeDirty/activate: Create getter/setter (zooGetX()/zooSetX() for each
  field. In these getters/setters, use activation/dirty methods. Is that good? 
  --> This would allow to use field-wise dirty-flags, which saves index updates (See DataSink1P)
  --> This would also help in situations where static or transient fields (methods) are used
      on objects whose persistence manager is closed. Access to such fields should not fail, 
      I guess.(?)

CONCURRENCY
- Allocate PAF-reader/writers on demand in methods. This is a little more effort,
  but allows much more concurrency, for example for writing indexes. But chaos during
  concurrent commit (two commits at once??). -> Should be prevented anyway.
  Problem: may allocate to many readers/writers.... -> Memory. -> Limited pool! 

DataDeserializerNoCLass is slow, because it reloads the page for every attribute....
And why is DataDeserializer not using an ObjectReader? -> seekPos() could be removed from PAFInput

TODO
- replace ArrayList iteration with [] iteration where possible
- PageAccessFile.seekPage: remove auto-paging, because it is always true! 
  + Move auto-paging into constructor
- Pack AtomicAccess and concurrent collection into CONCURRENT flag as in DDSPool.
- DDSPool: use also for Iterators! -> Currently, Pooling fails if raf is split() for pool .. ???
- (de-)serialize DBHashMap/DBVector not as Map, but as normal object (do not use slow put())
- Move object creation (deserialization) into cache?
- In future, DeSerializers should be 'handles'to the database. For example query-results should
  come with a DeSerializer for objects... -> allows concurrent queries

- Speed: See PerfNativeCall: IdentityHashMap is expensive. In (De)-Serializer: Remove usedClasses
  caching? Or limit it to an array of ten that is searched via ==? --> Test

TODO
- query: Do not check object for index-correctness! Instead check OID index and compare position.
  Otherwise we may read objects from non-existent pages! 
  WARNING: in theory the positions could match if the object has been updated twice! We still need
  to check the object itself!
- POS-Index proposal: Two types of entries: 
  a) POS->OID                   ->For example for object-deletion. 
  b) (pos+1) -> {nextPos | 0}   ->as currently
  Possibly:
  c) Offs=null or pos>>32: Number of objects on page? Easier recognize pages for FSM...
- Difference undefine/deleteSchema in SchemaIndex??? -> Delete FIELD indices! Delete PosIndex!

TODO
- Fix updating of index during commit for updated objects!
- Try undoing (for polepos) the single schema-oid per page. it seems to be expensive (?)
- try undoing int-index storag -> polepos.
- Check if we should replace PrimLongMapLI with LLIndex in ClientSessionCache

TESTs:
- Fix TestQueryOptimizer in test-tree (fails two of three)
- test pm.evict(not ALL)

PERF: seit 2011-10-05 ist update 100% teurer geworden (all polepos tests)!
  -> writing got slightly more expensive, however String.write() went from 2000 to 29xx (+50%)!
  -> int/short index storage???

- compare PrimLonMapLI with LLIndex and swithc in Cache to use the latter if possible.
  Should use less memory (no entry objects). It could get faster as well if page-exist-or-load
  checking is removed and COW property is removed for iteration (no find-interested-iterators)

PROF
  -> PrimMap get/put vs LongIndex get/put


PERF:
- Session.getHandle()
- Merge StateManager and Bundle -> Saves a ref in PCI and reduced initialization
- Use PCI.jdoFlags in activation method?
- DataDerserializer.readClass() Oid->ZooCLassDef->Class; then, in hollowForOID, we to CLass->ClassDef
  again via hashLookUp. This seems unnecessary. Should we always return ZooClassDef and use a 
  Fake-ZooCLassDef (isPersCapable=false) which is returned that contains the real class is not PC?
- Perform OGT implicitly during DataSerialization? avoids overhead... (?) But how about API 
  call-backs for users?
  -> Should completely avoid all the lists in OGT.
  -> Call-backs could be dangerous if they modify objects after they have been serialized.
     Solution: Use OGT, but only if callbacks have been installed.
  -> For makePersistent during serialization it would be useful to have one serializer per class,
     new persistent objects could then be passed between the serializers to the one that handles 
     it.
     
MEMORY
- FlatObjectWrite requires 81MB (ZooDB) versus 18MB (db4o)! -> see polepos-html

FSM:
- Test suite goes from 63 to 66 seconds when FSM index uses 4,1 instead of 8,1 ?!?!?!

FIX:
- attr-index adjust size to attr-size
- attr-index update when objects are deleted
- check difference pos-index/oid-index in CheckDB

FIELD-INDICES:
- ensure correct index update if index is created after instances are already dirty
- ensure correct index update if object was made transient before changed and made persistent again


Storage design:
- Should we store and OID index on each page or alternatively the length of each object?
  -> For example write objects to buffer first, then insert OID-index with offset and copy object
     data from buffer -> should be reasonably fast. 
     Or store object length with each object.
  Why? OID index would be 25% smaller.
  
- Should we consider single-page and multi-page objects? Would make sense if objects are written
  to buffer beforehand, so that length is known.
  Why? Maybe POS-Index could be smaller? Probably not

- Remove references to JDO/pm where possible and use Session instead? -> INdependence of JDO
  except for some interfaces (StateManager & PersistenceCapable (ObjectState))?
  -. Better for running it separately from JDO (smaller library)

PolePos:
- Fix Nested DELETE ?!?!?!?!
- Complex.delete (delete without loading objects, even through extents?
- Commits
- Query on inheritance hierarchy (when using ignoreCache = false)

Clean-up
- Move Config to a better place OR merge with ZooProperties????
- Big: move tests to separate src-tree
- Move JDO tests to separate folder?
- Remove Launcher code????

- implement/benchmark low-level queries
- Implement index-update during commit (buffer changes in memory from makeDirty calls)
- TestOidIndex.testDirtyPages fails when setting page size to 64
	
	
	
- Does FSM store int[]/byte[] instead of long/long?
- Does pos index store long/int i.o. long/long?

Design:
- Why are ZooClassDefs only avaiilable via _cache, not via _schemaManager? Why are schemas
  in both places?? -> We schould remove ISchema, or let ZooClassDef implement is (?) 
	
Query
- Subclass-indexing!
- Implement merging for overlap! / globalMoin/Max in optimizer
- Use Objects from cache if possible / required.
  !!! This also speeds up and generally improves finding duplicates, because we can use an 
  IdentityHashSet. -> Are we nod checking the cache already in the DeSerializer????
- In QueryImpl do no build up collection/set but, when possible,  return a special collection
  that loads objects dynamically from the iterator.
- Compile time ops? Well, in reality: at least check the query analysis & rewriting is avoided
  as much as possible if a query is executed multiple times.
  -> Trick: Exploit Object-Identity (and equality) of fixed query strings to recognize recurring 
     queries! 
	
Other:
- PolePos: Should (e.g. Sepang) be changed to use larger activation depth? I.e. load all Trees at
  once using a query on the class?
- Check why Zoo is slow in melbourne courses!!!
- implement DBList and DBMap to avoid set/map stuff in DataDeserializer
- Improve OGT: Do we need these HashMaps? Or could we use a flag (isSeen) in CachedObject instead?
- Allow disabling JDO extents? Would be equivalent to removing pos-index....
	
Perf:
- check why call to writeXYZ in PegaedObjectAccess are so expensive (Serializer.testLargeObjects()
- FSM: do not store flag?!?!
- look again at using MemoryMappedFile (possibly many of them, each 16 pages???). Would avoid
  a certain amount of copying. 
- optimize iterator nesting, e.g. in BarcelonaQuery! Also think about avoiding Iterator subclassing,
  each call costs avg=0.3ms (max=1.5ms)!!
- Investigate NIO 2.0! SeekableByteChannel / newByteChannel(...)
- Investigate hybrid FileAccess: mapped for existing file, unmapped for rest? Is remapping 
  easy/fast with NIO 2.0?
  
- Perf-Tools: JVM-Monitor, Jensor, Java Visual VM, Memory Analyzer
  
  ################################################# TODO ###################
- Allow definition of persistence capable interfaces! This allows avoiding expensive _usedClasses
  when deserializing certain fields! 
  Test with removing _usedObjects.clear(). Also: output calls to 
  DataDeserializer.readClassInfo()-> access to _usedClasses
	

  ############################# WeakReferences? ####################
- Are WeakReferences useful? Planned use is in subPage arrays in indices and in references from
  cached to actual objects. The penalty might be small, but if not, it may make sense to clean
  out references only during commit/rollback, effectively avoiding WeakReference traversal,
  and suitable for "main memory deployment" of databases.


  ###### JDO violation #####
- retainValues currently causes objects to become PERSISTENT_CLEAN during commit(). According
  to JDO they should become NON_TRANSACTIONAL_CLEAN intead.
    


************
Caching: 
========
Do not implement binary-page caching! The operating system and hard drive do that 
automatically, probably faster, more efficient and also share the cache with other applications.
Otherwise the pages would be cached twice in memory!
If we want to do caching, we could cache some deserialized pages... . Still expensive in terms
of memory (double caching), but it may actually improve performance by avoiding frequent
deserialization. Candidates???  
	
************
Single user/single tx advantages:
- no locking required
- no checks required during optimistic commit
- no need to invalidate cached objects during commit!!!!!! -> Can not become invalid!
************

MultiThreading:
- Avoid static in OGT by using ZooCLassDefs from cached objects i.o. own. Or at least make it
  non-static.
	
Index:	
- Turn Schemata into objects using PagedObjectAccess -> allows proper use of FSM ->
  check in PagedObjectAccess for POA-callback==null not required.
		
- Test harness for index creation and updates (i.e. object changes value)
- Implement InMemoryDB in Avon
- Test & implement: Queries should consider cached (and possibly modified) objects

- Use inner pages as value store? Improves a few lookups. More complicated? -> Avoid complexity. 
- Copy to previous page after put(). -> merge destroys optimization for unique-values-split, or does it?
  OIDS: 1) next does not exist. 2) Previous exists, but may not be full (but should be) -> copy to prev
  How about: In general always fill up pages to limit, never move to neighbour pages, unless neighbour
  pages exists?
	
- Check counted B-Tree:
http://www.chiark.greenend.org.uk/~sgtatham/algorithms/cbtree.html

- Decide on concurrency pattern for BucketArrayList iterator (see javadoc of iterator).


Perf:
- Consider ConcurrentSkipLists, e.g. for cache/OGT. Needs confirmation, but probably does not use an 
	array and is therefore better for adding objects (no array resizing). 
- LongMap: Use internally bucket-arrays?!?!
         transfer is very expensive (15%of total time, 25% of makePersistentTime()!) 
                    Test after removing GENERIC stuff???
- If iterating over iterators in markPageDirtyAndClone() takes to long, turn iterators into list-
  elements with prev-next references. Delete happens then directly w.o. call to ABstractPagedIndex.
	
Major short term goals:
- indices in queries
- use smaller index entries for types shorter than 'long'?
- Schema evolution

- improve index page usage:
  a) When splitting, first attempt to distribute over subsequent and previous page. This should 
     satisfy evenly distributed insertions, even with b) in place.
  b) If a) fails, create new page that contains 25%(33%?) of the entries. This should satisfy
     increasing numbers. For decreasing numbers, this should also work, because an overflowing
     page first distribute to neighbouring pages. Question: do we need b) at all? Probably not! 
     At least not, if previous and following pages are always (both?) filled. 	
  -> Fix MAX_DEPTH constants in Index tests!
	
	
- Test QUery/Extent with cache: new/deleted/modified objects (ignoreCache on/off)
	
- Make MergingIterator multi-threaded (see TODO in class)
- Use LongMap in ClientSessionCache. AddMap<Object, CachedObject> -> see FindCO(PC)? 
  Or rather a statemanager instance per PC?
- do not load all objects! Activation depth infinity

- in rollback(): Use hollow objects instead of refreshing everything!

- Iterators (e.g. in indices): use pattern from QueryIterator: move to nextElement in findNext(),
  hasNext() returns (next!=null);

- In SerializerTools, use specialized or IdentityMap
  CHanging from HashMap/Map to IdentityMaps already increased Testharnesses from 29sec to 21 secs!!!
- (De-)Serializer: Fix loading of Keys in Sets and Maps (See TODOs).

- preemptive commit()? -> Store objects asynchronously (no flush) when they get makeDirty()???
  -> track application: how likely is a rollback()? how often are objects changed after first change?
  To handle preemptive commit, reset the pageCount if the writer to the count as it was before the
  preemptive commit was initiated. 

- rename nEntries to nKeys
- deRegister/invalidate iterators on commit/rollback()
- deregister iterator when hasNext()==false

- indices in queries
- clean up index implementation

- JDO 3.0 (&2.0?) does not require byte code enhancement!

- Optimize Page size (16KB? 4KB?)

- Pos/schema index. should we remove this? If it is only used to speed up queries that have other-
  wise no index, then it may be better to scrap it.... (?). 

- Freespace manager 2.0:
  Use separate index for free pages. Do not use a BitMap, that would only pay out if more than 1/32
  of all pages would be free.
  The manager should only return pages that were freed up during previous transactions, but not
  in the current one. To do so, in the freespace manager, create a new iterator(MIN_INT/MAX_INT) for
  every new transaction. The iterator will return only free pages from previous transactions.
  If (iter.hasNext() == false), use atomic page counter to allocate additional pages.
  
- Freespace manager: see below
- Large Objects / free-space manager: Create non-unique OID index, contains one entry per oid-page 
  pair. Allows for non-consecutive writes, e.g. when re-using freed up pages, also avoid the POS 
  entry at the end of each page. -> This could lead to other optimisations in PageAccessFile(?).
  The POS index contains all pages. -> effectively, we have now a free-space manager. If the POS
  manager has no other objects on that page, then the page is free. 

- TODO PagedObjectAccess tries to group object into pages, while the underlying PageAccessFile just
  writes a continuous stream of objects. Fix this! -> Probably just fix the PagedObjectAccess.
  -> Result: All objects, regardless of size are just written one after the other in a continuous
    stream. A new stream is only started for a new class (rationale???? Why not simply a continuous
    stream for all objects? -> grouping is good for queries and schema evolution. But would it be
    harmfull if objects of different class would be on a page as long as they are generally sorted 
    by class? The benefit would be that a) a transaction may just write a single data page, if 
    multiple small objects of different classes are involved. b) it makes future implementation
    of clustering simpler.).
    On the other hand, if we would dedicate pages to a specific class, we could start filling
    up half-full pages of smaller object over multiple transactions. That slows down writing, 
    because we may have to read the old page first, and not all objects may fit on the new page.
    But subsequent reading (e.g. for queries) may be faster, because the objects are spread over
    fewer pages. We then should also distinguish small and large objects, the latter ones would
    otherwise risk to have their tail moved to a different area on the disk.


READ Java news #15 / #98  -> Don't use weak refs in Cache!



Commit optimization
-------------------
Use separate thread for 'optimistic' serialization, hoping that objects do not change again.
-> Measure times serialization<->index_update<->write+flush()
-> patentable?????

Asynchronous flush().
-> Measure whether flush() really blocks.
If it does, perform it asynchronously in a separate thread. However subsequent read/write-ops 
should block until flush() is finished.



publishable?
============
-> improved B_Tree filling? (unique, merge with prev and subsequent)
-> FSM solution to page allocation problem? 