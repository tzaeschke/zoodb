TODO Java 9:
- Java 9 has an enhanced String class that stores Strings as 1-byte-chars UNLESS UTF-16 is required!
  -> Do the same in ZooDB?

TODO SSD (28.4.2015)
- SSD use internally something similar to COW:
  http://arstechnica.com/gadgets/2015/04/27/ask-ars-my-ssd-does-garbage-collection-so-i-dont-need-trim-right/
  http://arstechnica.com/information-technology/2012/06/04/inside-the-ssd-revolution-how-solid-state-disks-really-work/
  Would it be possible to exploit this, for example by directly accessing the SSD blocks, for 
  example by means of an own file-system (ZooFS)???
- Or, at a higher level, benefit from working with BtrFS?
- Apparently SSD have 8KB pages


Check ReflectASM: For generating fast access methods
https://github.com/EsotericSoftware/reflectasm
https://www.grey-panther.net/2016/08/how-slow-is-java-reflection.html

Check ByteBuffer:
http://mail.openjdk.java.net/pipermail/core-libs-dev/2016-July/042286.html

Check "Flexible Paxos":
https://blog.acolyer.org/2016/09/27/flexible-paxos-quorum-intersection-revisited

Consider Java Dynamic Proxies for API logging.

TODO: Simplify!!!!
- Simplify client-commit!!! Why do we separate delete/update/new? For unique attribute indexes, 
  we anyway need to use the 'retry-later-in-case-of-conflict' approach.
  Thus, we don't need separate dirty/delete lists...
- Also, consider doing OGT on the fly while extracting dirty/delete objects. This would reduce
  the number of required loops through all objects.
- Plus, consider setting ObjectStates in same loop as storing objects. But that could be difficult,
  how do we rollback in case of uniqueness- of MVCC-conflict? No need to, we anyway set everything
  to hollow... . This setting to 'hollow'/'clean' can also be used in the OGT to identify 'seen' 
  objects!
- Do we need sinks on the client? Maybe they should only be on the server? This would simplify
  optimisations, for example using just one network call if there is only on object of each class.     

TODO 
- Consider again: PersCapable as Interface
- Queries, for example involving the cache, currently materialize the result. This avoids conflicts
  with iterators over the query cache. In future, we could only materialise the part from the 
  cache, especially, we could only materialise it on demand if the cache is about to change.
  On the other hand, all the sorting requires materialisation anyway, ....

TODO
- Migrate FSM to use IndexFactory.

TODO
- Generic objects (GOs) and GOProxy (GOPs):
  Mixing PC and GOs is impossible, because PCs/SCOs may contain typed references which cannot be 
  set to GO, only to a GOP. Pure GO structures sound feasible, but need to be done carefully,
  they need to include DBCollection classes (why? because it is simpler?) and SCOs, which is much
  harder to achieve (non-persistent capable generic objects). It also hard because SCOs may actually
  be java classes which are already loaded, or custom sub-classes of java classes. 
  Use of GOPs seems easier.
  Using GOPs seems to simplify things, however once they are loaded, they cannot be unloaded
  if the actual real class is required. That means that GOPs are strictly forbidden if the real 
  class is available. 
  While GOPs can be very useful for class-path independent import/export, they cannot be used
  during schema evolution because they cannot be evolved.
  One problem with strict separation of GO/PC: For example during schema evolution, if a GO field
  is set through the Handle-API, the value may be an SCO such as an array. But to maintain the
  separation of GO/PC, this means that the array and all that it contains(!!!) such as other SCOs
  or PCs need to be turned into GOs. Or: we allow references from GO to PC but not the other way
  around...
  TBD.
  Import/export should work fine with pure GenericObjects (+generic SCOs). Import/export should also
  keep using GOs/GOPs in order to allow dynamic import of XMLs(?).
  Schema evolution is more complicated.
  Why NOT use GOP?
  a) Once they are loaded, they block loading of proper classes! This includes
     all GOP-super-classes that they create.
  b) They cannot be evolved! -> Useless during schema evolution.

TODO 
- Turn each index into its own channel? This could be useful for parallellism but also for the 
  following point:
- Space waste through small commits. After a small commit (last written data page is < 1/2 full)
  and if the next commit is also small (or even if it is not), copy the previous page and add the
  new objects to the page. Object of the previous page will have to be re-indexed (pos/oid).
  Take care with object that get updated, they should not be twice on the page!

TODO
- Migration away from JDO:
  - Use DBLogger to throw exceptions. May use ENUM i.o. different methods for exception type.
- Perf-significant-size:
  - store object offset in data-page
  - index-prefixing

TODO
- IMPORTANT: setOID() will not work, because in references we also store the schemaOID, which
  may not fit anymore after setOID().
  Looking up the schema oid at the target's object page is expensive.
  Solutions:
  a) Store the schemaOID in the OID index. -> Index gets bigger (store only 32bit schemaID?), but 
     Objects get smaller. In effect, the schema is stored once per object, not once per reference
     to that objects, which may be an advantage in case of multiple references to that object.
  b) Improve activation, such that references are only activated when they are followed (lazy
     activation). Question: where do we store the referenced OID before the activation while
     the object is already materialised? Abuse the index-update-array for that?
     Advantage: Stored objects get smaller; referenced objects are only materialised when required
     (faster, less memory); Index sizes stay the same. Disadvantage: requires (complicated?)
     byte-code enhancement/activation and intermediate storage of OID. 

CLEAN-UP 
remove ObjectReader?!?!? Or changing DataDeSerializer.in to SerialInput

TAGS
- When storing e.g. 15.000.000 objects, commit becomes very slow (every 10.000). This is
  presumably because commit() iterates over the whole cache. Rethink again if separate
  Sets for dirty object could be useful.

MAJOR:
- Read-objects w/o instantiation -> Allows reading DB with evolved classes!
- WeakRefs for IndexPages (use additional fixed-ref to avoid collection if page is dirty
- WeakRefs for objects. -> PrimLongLIMap<Long,WeakRef<ZooPCImpl>> ?
- Other query stuff
- Schema evolution
- Client-Server mode
- Separate JDO from ZOO-API --> Allow advanced features such as atomic updates.
- Think about SCO double-serialization. Can that be sensibly avoided???
- Generate classes for (de-)serializing objects, one class for each persistent class.
  Use Eclipse to see byte-code of example class?
  
- store only 32 pages, offset could be on page (upfront, or in batches between groups of objects).
  Think about distinguishing single-page and multi-page objects. 
  
- Optimise Index: Create realms/kingdoms/county/country/region to reduce size of stored OIDs.
  Initially there would be one region per bit>32, stored keys (values for field-indices) would 
  be only 32 bit.
  This could be multi-level, storing only the last 8 or 16 bit of a key/value. In extremo this
  would be adaptive, storing as many bit as are required to fill a page.
  
- Multi-file approach! File-positions could all become 32bit, at least when stored on disk.
  -> Faster, less space. In memory, the first part of long-pos could be used as file ID.
  -> Best if Each file has separate indices for everything (except schema data?).
     Then file updates could be performed concurrently. There would be separate
     DataSinks(or similar) for each file...
  -> With fixed max-size, we should try the MemoryMapped files again.

Transactional consistency: Iterators(Queries/extents) over transaction boundaries.
  -> See design.txt. To fix this we would need a class index that just contains OIDs...
     These class indices could then be inserted optionally to improve queries.
  -> The pos-index could also become half the size, containing only positions. For what
     do we need the next-position info? That Is probably only useful during deletion
     to avoid loading the page for finding follow-up pages.
     Should we use the last bit of the position (which is always even) to indicate
     that the object is/is not continued on another page?
     Or a second entry with the same value but uneven last bit?
     -> There would then be one more index to update, however the required disk-space
     	should be the same....   But the OID-class-index may also be slower, as it reads
     	objects out of order, a page may be read multiple times.
     See test TestPosIndex_002 and Test_062
     
     Refreshing the iterators also needs to be refactored in case the iterators belong
     to different transactions (future: parallel transactions)
     
       
MemoryMapped Files:
- Use multiple MM-Files per file, e.g. 64K/128K. Not too much waste for small DB, still efficient to 
  resize(?)
  http://www.linuxtopia.org/online_books/programming_books/thinking_in_java/TIJ314_029.htm   
  Many small MMFIle-view for a large file?
  Cost (also memory, delayed GC) of discarding MM files and replacing them with a single bigger one?
  Cheap?(just map memory again)? Expensive?
- Test: May only pay of for large files?
- See also:
  https://en.wikipedia.org/wiki/Memory-mapped_file
  http://docs.oracle.com/javase/7/docs/api/java/nio/channels/FileChannel.html
- DIRECT READ: Memory mapped file: Indexes could benefit, or not? If a page is not updated, it 
  could read its content directly from a mem-mapped file, every time it needs the content. Or would 
  that be slower?
- Bugs: http://stas-blogspot.blogspot.ch/2009/02/mmeory-mapped-files-in-java-easy.html
- http://www.javacodegeeks.com/2012/01/using-memory-mapped-file-for-huge.html
- VERY GOOD:  Details+refs
  http://www.kdgregory.com/index.php?page=java.byteBuffer



URGENT:
- Check that dropInstance/deleteAll remove entries from ALL indices (also POS and FIELD)!
- Why does it take so much longer if indexes/classes are removed as well? Because index usage takes
  time? -> Still slower if indexes are disabled in test!!!!!
  -> Also dropInstances is sometimes slower (1 sec.) than delete?!?!? SHould be faster?

- In DataDeSerializer, don't use cache.getSchema(Node, x), because that requires an
  additional HashMap lookup. Instead use locally stored version of schemas for that node.
  -> May only make sense if Deserializer is only created once per session(?). 

COPYRIGHT
- PrimLongMapLI
- PrimLongTreeMap
- WeakIdentityHashMap

DataSinks
- See TODOs in DataSink and DataDeleteSink


BCE
- Efficient insertion of makeDirty/activate: Create getter/setter (zooGetX()/zooSetX() for each
  field. In these getters/setters, use activation/dirty methods. Is that good? 
  --> This would allow to use field-wise dirty-flags, which saves index updates (See DataSink1P)
  --> This would also help in situations where static or transient fields (methods) are used
      on objects whose persistence manager is closed. Access to such fields should not fail, 
      I guess.(?)

CONCURRENCY
- Allocate PAF-reader/writers on demand in methods. This is a little more effort,
  but allows much more concurrency, for example for writing indexes. But chaos during
  concurrent commit (two commits at once??). -> Should be prevented anyway.
  Problem: may allocate to many readers/writers.... -> Memory. -> Limited pool! 

DataDeserializerNoCLass is slow, because it reloads the page for every attribute....
And why is DataDeserializer not using an ObjectReader? -> seekPos() could be removed from PAFInput

TODO
- replace ArrayList iteration with [] iteration where possible
- PageAccessFile.seekPage: remove auto-paging, because it is always true! 
  + Move auto-paging into constructor
- Pack AtomicAccess and concurrent collection into CONCURRENT flag as in DDSPool.
- DDSPool: use also for Iterators! -> Currently, Pooling fails if raf is split() for pool .. ???
- (de-)serialize DBHashMap/DBVector not as Map, but as normal object (do not use slow put())
- Move object creation (deserialization) into cache?
- In future, DeSerializers should be 'handles'to the database. For example query-results should
  come with a DeSerializer for objects... -> allows concurrent queries

- Speed: See PerfNativeCall: IdentityHashMap is expensive. In (De)-Serializer: Remove usedClasses
  caching? Or limit it to an array of ten that is searched via ==? --> Test

TODO
- query: Do not check object for index-correctness! Instead check OID index and compare position.
  Otherwise we may read objects from non-existent pages! 
  WARNING: in theory the positions could match if the object has been updated twice! We still need
  to check the object itself!
- POS-Index proposal: Two types of entries: 
  a) POS->OID                   ->For example for object-deletion. 
  b) (pos+1) -> {nextPos | 0}   ->as currently
  Possibly:
  c) Offs=null or pos>>32: Number of objects on page? Easier recognize pages for FSM...
- Difference undefine/deleteSchema in SchemaIndex??? -> Delete FIELD indices! Delete PosIndex!

TODO
- Try undoing (for polepos) the single schema-oid per page. it seems to be expensive (?)
- try undoing int-index storag -> polepos.
- Check if we should replace PrimLongMapLI with LLIndex in ClientSessionCache

TESTs:
- Fix TestQueryOptimizer in test-tree (fails two of three)
- test pm.evict(not ALL)

PERF: seit 2011-10-05 ist update 100% teurer geworden (all polepos tests)!
  -> writing got slightly more expensive, however String.write() went from 2000 to 29xx (+50%)!
  -> int/short index storage???

- compare PrimLonMapLI with LLIndex and swithc in Cache to use the latter if possible.
  Should use less memory (no entry objects). It could get faster as well if page-exist-or-load
  checking is removed and COW property is removed for iteration (no find-interested-iterators)

PROF
  -> PrimMap get/put vs LongIndex get/put


PERF:
- Session.getHandle()
- Merge StateManager and Bundle -> Saves a ref in PCI and reduced initialization
- Use PCI.jdoFlags in activation method?
- DataDerserializer.readClass() Oid->ZooCLassDef->Class; then, in hollowForOID, we to CLass->ClassDef
  again via hashLookUp. This seems unnecessary. Should we always return ZooClassDef and use a 
  Fake-ZooCLassDef (isPersCapable=false) which is returned that contains the real class is not PC?
- Perform OGT implicitly during DataSerialization? avoids overhead... (?) But how about API 
  call-backs for users?
  -> Should completely avoid all the lists in OGT.
  -> Call-backs could be dangerous if they modify objects after they have been serialized.
     Solution: Use OGT, but only if callbacks have been installed.
  -> For makePersistent during serialization it would be useful to have one serializer per class,
     new persistent objects could then be passed between the serializers to the one that handles 
     it.
     
MEMORY
- FlatObjectWrite requires 81MB (ZooDB) versus 18MB (db4o)! -> see polepos-html

FSM:
- Test suite goes from 63 to 66 seconds when FSM index uses 4,1 instead of 8,1 ?!?!?!

FIX:
- attr-index adjust size to attr-size
- attr-index update when objects are deleted
- check difference pos-index/oid-index in CheckDB

FIELD-INDICES:
- ensure correct index update if index is created after instances are already dirty
- ensure correct index update if object was made transient before changed and made persistent again


Storage design:
- Should we store and OID index on each page or alternatively the length of each object?
  -> For example write objects to buffer first, then insert OID-index with offset and copy object
     data from buffer -> should be reasonably fast. 
     Or store object length with each object.
  Why? OID index would be 25% smaller.
  
- Should we consider single-page and multi-page objects? Would make sense if objects are written
  to buffer beforehand, so that length is known.
  Why? Maybe POS-Index could be smaller? Probably not

- Remove references to JDO/pm where possible and use Session instead? -> INdependence of JDO
  except for some interfaces (StateManager & PersistenceCapable (ObjectState))?
  -. Better for running it separately from JDO (smaller library)

Clean-up
- Move Config to a better place OR merge with ZooProperties????
- Big: move tests to separate src-tree
- Move JDO tests to separate folder?
- Remove Launcher code????

- implement/benchmark low-level queries
- Implement index-update during commit (buffer changes in memory from makeDirty calls)
- TestOidIndex.testDirtyPages fails when setting page size to 64
	
	
	
- Does FSM store int[]/byte[] instead of long/long?
- Does pos index store long/int i.o. long/long?

Design:
- Why are ZooClassDefs only avaiilable via _cache, not via _schemaManager? Why are schemas
  in both places?? -> We schould remove ISchema, or let ZooClassDef implement is (?) 
	
Query
- Subclass-indexing!
- Implement merging for overlap! / globalMoin/Max in optimizer
- Use Objects from cache if possible / required.
  !!! This also speeds up and generally improves finding duplicates, because we can use an 
  IdentityHashSet. -> Are we nod checking the cache already in the DeSerializer????
- In QueryImpl do no build up collection/set but, when possible,  return a special collection
  that loads objects dynamically from the iterator.
- Compile time ops? Well, in reality: at least check the query analysis & rewriting is avoided
  as much as possible if a query is executed multiple times.
  -> Trick: Exploit Object-Identity (and equality) of fixed query strings to recognize recurring 
     queries! 
	
Other:
- PolePos: Should (e.g. Sepang) be changed to use larger activation depth? I.e. load all Trees at
  once using a query on the class?
- Check why Zoo is slow in melbourne courses!!!
- implement DBList and DBMap to avoid set/map stuff in DataDeserializer
- Improve OGT: Do we need these HashMaps? Or could we use a flag (isSeen) in CachedObject instead?
- Allow disabling JDO extents? Would be equivalent to removing pos-index....
	
Perf:
- check why call to writeXYZ in PegaedObjectAccess are so expensive (Serializer.testLargeObjects()
- FSM: do not store flag?!?!
- look again at using MemoryMappedFile (possibly many of them, each 16 pages???). Would avoid
  a certain amount of copying. 
- optimize iterator nesting, e.g. in BarcelonaQuery! Also think about avoiding Iterator subclassing,
  each call costs avg=0.3ms (max=1.5ms)!!
- Investigate NIO 2.0! SeekableByteChannel / newByteChannel(...)
- Investigate hybrid FileAccess: mapped for existing file, unmapped for rest? Is remapping 
  easy/fast with NIO 2.0?
  
- Perf-Tools: JVM-Monitor, Jensor, Java Visual VM, Memory Analyzer
  
  ################################################# TODO ###################
- Allow definition of persistence capable interfaces! This allows avoiding expensive _usedClasses
  when deserializing certain fields! 
  Test with removing _usedObjects.clear(). Also: output calls to 
  DataDeserializer.readClassInfo()-> access to _usedClasses
	

  ############################# WeakReferences? ####################
- Are WeakReferences useful? Planned use is in subPage arrays in indices and in references from
  cached to actual objects. The penalty might be small, but if not, it may make sense to clean
  out references only during commit/rollback, effectively avoiding WeakReference traversal,
  and suitable for "main memory deployment" of databases.


  ###### JDO violation #####
- retainValues currently causes objects to become PERSISTENT_CLEAN during commit(). According
  to JDO they should become NON_TRANSACTIONAL_CLEAN instead.
    


************
Caching: 
========
Do not implement binary-page caching! The operating system and hard drive do that 
automatically, probably faster, more efficient and also share the cache with other applications.
Otherwise the pages would be cached twice in memory!
If we want to do caching, we could cache some deserialized pages... . Still expensive in terms
of memory (double caching), but it may actually improve performance by avoiding frequent
deserialization. Candidates???  
	
************
Single user/single tx advantages:
- no locking required
- no checks required during optimistic commit
- no need to invalidate cached objects during commit!!!!!! -> Cannot become invalid!
************

MultiThreading:
- Avoid static in OGT by using ZooCLassDefs from cached objects i.o. own. Or at least make it
  non-static.
	
Index:	
- Turn Schemata into objects using PagedObjectAccess -> allows proper use of FSM ->
  check in PagedObjectAccess for POA-callback==null not required.
		
- Test harness for index creation and updates (i.e. object changes value)
- Implement InMemoryDB in Avon
- Test & implement: Queries should consider cached (and possibly modified) objects

- Use inner pages as value store? Improves a few lookups. More complicated? -> Avoid complexity. 
- Copy to previous page after put(). -> merge destroys optimization for unique-values-split, or does it?
  OIDS: 1) next does not exist. 2) Previous exists, but may not be full (but should be) -> copy to prev
  How about: In general always fill up pages to limit, never move to neighbour pages, unless neighbour
  pages exists?
	
- Check counted B-Tree:
http://www.chiark.greenend.org.uk/~sgtatham/algorithms/cbtree.html

- Decide on concurrency pattern for BucketArrayList iterator (see javadoc of iterator).


Perf:
- Consider ConcurrentSkipLists, e.g. for cache/OGT. Needs confirmation, but probably does not use an 
	array and is therefore better for adding objects (no array resizing). 
- LongMap: Use internally bucket-arrays?!?!
         transfer is very expensive (15%of total time, 25% of makePersistentTime()!) 
                    Test after removing GENERIC stuff???
- If iterating over iterators in markPageDirtyAndClone() takes to long, turn iterators into list-
  elements with prev-next references. Delete happens then directly w.o. call to ABstractPagedIndex.
	
Major short term goals:
- indices in queries
- use smaller index entries for types shorter than 'long'?
- Schema evolution

- improve index page usage:
  a) When splitting, first attempt to distribute over subsequent and previous page. This should 
     satisfy evenly distributed insertions, even with b) in place.
  b) If a) fails, create new page that contains 25%(33%?) of the entries. This should satisfy
     increasing numbers. For decreasing numbers, this should also work, because an overflowing
     page first distribute to neighbouring pages. Question: do we need b) at all? Probably not! 
     At least not, if previous and following pages are always (both?) filled. 	
  -> Fix MAX_DEPTH constants in Index tests!
	
	
- Test QUery/Extent with cache: new/deleted/modified objects (ignoreCache on/off)
	
- Make MergingIterator multi-threaded (see TODO in class)
- Use LongMap in ClientSessionCache. AddMap<Object, CachedObject> -> see FindCO(PC)? 
  Or rather a statemanager instance per PC?
- do not load all objects! Activation depth infinity

- in rollback(): Use hollow objects instead of refreshing everything!

- Iterators (e.g. in indices): use pattern from QueryIterator: move to nextElement in findNext(),
  hasNext() returns (next!=null);

- In SerializerTools, use specialized or IdentityMap
  CHanging from HashMap/Map to IdentityMaps already increased Testharnesses from 29sec to 21 secs!!!
- (De-)Serializer: Fix loading of Keys in Sets and Maps (See TODOs).

- preemptive commit()? -> Store objects asynchronously (no flush) when they get makeDirty()???
  -> track application: how likely is a rollback()? how often are objects changed after first change?
  To handle preemptive commit, reset the pageCount if the writer to the count as it was before the
  preemptive commit was initiated. 

- rename nEntries to nKeys
- deRegister/invalidate iterators on commit/rollback()
- deregister iterator when hasNext()==false

- indices in queries
- clean up index implementation

- JDO 3.0 (&2.0?) does not require byte code enhancement!

- Optimize Page size (16KB? 4KB?)

- Pos/schema index. should we remove this? If it is only used to speed up queries that have other-
  wise no index, then it may be better to scrap it.... (?). 

- Freespace manager 2.0:
  Use separate index for free pages. Do not use a BitMap, that would only pay out if more than 1/32
  of all pages would be free.
  The manager should only return pages that were freed up during previous transactions, but not
  in the current one. To do so, in the freespace manager, create a new iterator(MIN_INT/MAX_INT) for
  every new transaction. The iterator will return only free pages from previous transactions.
  If (iter.hasNext() == false), use atomic page counter to allocate additional pages.
  
- Freespace manager: see below
- Large Objects / free-space manager: Create non-unique OID index, contains one entry per oid-page 
  pair. Allows for non-consecutive writes, e.g. when re-using freed up pages, also avoid the POS 
  entry at the end of each page. -> This could lead to other optimisations in PageAccessFile(?).
  The POS index contains all pages. -> effectively, we have now a free-space manager. If the POS
  manager has no other objects on that page, then the page is free. 

- TODO PagedObjectAccess tries to group object into pages, while the underlying PageAccessFile just
  writes a continuous stream of objects. Fix this! -> Probably just fix the PagedObjectAccess.
  -> Result: All objects, regardless of size are just written one after the other in a continuous
    stream. A new stream is only started for a new class (rationale???? Why not simply a continuous
    stream for all objects? -> grouping is good for queries and schema evolution. But would it be
    harmfull if objects of different class would be on a page as long as they are generally sorted 
    by class? The benefit would be that a) a transaction may just write a single data page, if 
    multiple small objects of different classes are involved. b) it makes future implementation
    of clustering simpler.).
    On the other hand, if we would dedicate pages to a specific class, we could start filling
    up half-full pages of smaller object over multiple transactions. That slows down writing, 
    because we may have to read the old page first, and not all objects may fit on the new page.
    But subsequent reading (e.g. for queries) may be faster, because the objects are spread over
    fewer pages. We then should also distinguish small and large objects, the latter ones would
    otherwise risk to have their tail moved to a different area on the disk.


READ Java news #15 / #98  -> Don't use weak refs in Cache!



Commit optimization
-------------------
Use separate thread for 'optimistic' serialization, hoping that objects do not change again.
-> Measure times serialization<->index_update<->write+flush()
-> patentable?????

Asynchronous flush().
-> Measure whether flush() really blocks.
If it does, perform it asynchronously in a separate thread. However subsequent read/write-ops 
should block until flush() is finished.



publishable?
============
-> improved B_Tree filling? (unique, merge with prev and subsequent)
-> FSM solution to page allocation problem? 
